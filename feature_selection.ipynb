{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col, split\n",
    "\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "users_df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/Users/monisha/Desktop/USC/ThirdSemester/CSCI541-DataMining/Project/allusers_2000.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_toPandas = users_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- review_count: integer (nullable = true)\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- fans: integer (nullable = true)\n",
      " |-- yelping_since_year: integer (nullable = true)\n",
      " |-- friends_count: integer (nullable = true)\n",
      " |-- elite_count: integer (nullable = true)\n",
      " |-- group: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "array = users_toPandas.values\n",
    "users_df.printSchema()\n",
    "X = array[:,1:7]\n",
    "Y = array[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "Num Features: 1\n",
      "['user_id', 'review_count', 'average_stars', 'fans', 'yelping_since_year', 'friends_count', 'elite_count', 'group']\n",
      "Selected Features: [False False False False False  True]\n",
      "Feature Ranking: [6 2 4 3 5 1]\n"
     ]
    }
   ],
   "source": [
    "#Recursive feature eliminations\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pandas import read_csv\n",
    "url = \"/Users/monisha/Desktop/USC/ThirdSemester/CSCI541-DataMining/Project/allusers_2000.csv\"\n",
    "names = ['user_id','review_count','average_stars','fans','yelping_since_year','friends_count','elite_count','group']\n",
    "dataframe = read_csv(url,header = 0)\n",
    "array = dataframe.values\n",
    "X = array[:,1:7]\n",
    "print type(X)\n",
    "Y = array[:,7]\n",
    "Y = Y.astype('int')\n",
    "print type(Y)\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "\n",
    "rfe = RFE(model, 1)\n",
    "rfe = rfe.fit(X, Y)\n",
    "# summarize the selection of the attributes\n",
    "print(\"Num Features: %d\") % rfe.n_features_\n",
    "print names\n",
    "print(\"Selected Features: %s\") % rfe.support_\n",
    "print(\"Feature Ranking: %s\") % rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
